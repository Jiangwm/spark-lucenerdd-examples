{
  "paragraphs": [
    {
      "title": "Load Spark LuceneRDD Jars",
      "text": "%dep\nz.addRepo(\"Spark Packages Repo\").url(\"http://dl.bintray.com/spark-packages/maven\")\nz.addRepo(\"OSS SNAPSHOTS\").url(\"https://oss.sonatype.org/content/repositories/snapshots\")\nz.load(\"org.zouzias:spark-lucenerdd_2.11:0.2.2-SNAPSHOT\")",
      "dateUpdated": "Oct 16, 2016 8:35:13 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "title": true,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {},
          "map": {
            "baseMapType": "Streets",
            "isOnline": true,
            "pinCols": []
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1475350705756_458300089",
      "id": "20161001-115642_482200633",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "Must be used before SparkInterpreter (%spark) initialized\nHint: put this paragraph before any Spark code and restart Zeppelin/Interpreter"
      },
      "dateCreated": "Oct 1, 2016 7:38:25 AM",
      "dateStarted": "Oct 16, 2016 8:35:13 AM",
      "dateFinished": "Oct 16, 2016 8:35:13 AM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Imports for spark-lucenerdd",
      "text": "import org.apache.spark.SparkConf\nimport org.apache.spark.sql.{Row, SparkSession}\nimport org.apache.spark.sql.SparkSession\nimport org.zouzias.spark.lucenerdd.LuceneRDD\nimport org.zouzias.spark.lucenerdd._\nimport org.zouzias.spark.lucenerdd.logging.Logging\n",
      "dateUpdated": "Oct 16, 2016 8:35:13 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "title": true,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {},
          "map": {
            "baseMapType": "Streets",
            "isOnline": true,
            "pinCols": []
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1475350705757_457915340",
      "id": "20161001-120020_440303718",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.SparkConf\n\nimport org.apache.spark.sql.{Row, SparkSession}\n\nimport org.apache.spark.sql.SparkSession\n\nimport org.zouzias.spark.lucenerdd.LuceneRDD\n\nimport org.zouzias.spark.lucenerdd._\n\nimport org.zouzias.spark.lucenerdd.logging.Logging\n"
      },
      "dateCreated": "Oct 1, 2016 7:38:25 AM",
      "dateStarted": "Oct 16, 2016 8:35:13 AM",
      "dateFinished": "Oct 16, 2016 8:35:16 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Load DBLP \u0026 Scholar datasets",
      "text": "val scholarDF \u003d spark.read.parquet(\"data/linkage-papers1/linkage-papers-scholar.parquet\")\nval dblpDF \u003d spark.read.parquet(\"data/linkage-papers1/linkage-papers-dblp.parquet\")\nval groundTruthDF \u003d spark.read.parquet(\"data/linkage-papers1/linkage-papers-scholar-vs-dblp.parquet\")\n\nval scholar \u003d scholarDF.select(\"id\", \"title\", \"authors\", \"venue\")\n\nval dblp \u003d LuceneRDD(dblpDF)\ndblp.cache()\ndblp.fields()",
      "dateUpdated": "Oct 16, 2016 8:35:13 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "title": true,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {},
          "map": {
            "baseMapType": "Streets",
            "isOnline": true,
            "pinCols": []
          }
        },
        "enabled": true,
        "tableHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1475350705768_441371138",
      "id": "20161001-145632_657667869",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nscholarDF: org.apache.spark.sql.DataFrame \u003d [id: string, title: string ... 3 more fields]\n\ndblpDF: org.apache.spark.sql.DataFrame \u003d [id: string, title: string ... 3 more fields]\n\ngroundTruthDF: org.apache.spark.sql.DataFrame \u003d [idDBLP: string, idScholar: string]\n\nscholar: org.apache.spark.sql.DataFrame \u003d [id: string, title: string ... 2 more fields]\n\ndblp: org.zouzias.spark.lucenerdd.LuceneRDD[org.apache.spark.sql.Row] \u003d LuceneRDD[872] at RDD at LuceneRDD.scala:40\n\nres150: dblp.type \u003d LuceneRDD[872] at RDD at LuceneRDD.scala:40\n\nres151: Set[String] \u003d Set(year, id, authors, title, venue)\n"
      },
      "dateCreated": "Oct 1, 2016 7:38:25 AM",
      "dateStarted": "Oct 16, 2016 8:35:14 AM",
      "dateFinished": "Oct 16, 2016 8:35:19 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "def tokenizer(s: String, threshold: Int, comb: String \u003d \"OR\"): String \u003d {\n    s.split(\" \").map(_.replaceAll(\"[^a-zA-Z0-9]\", \"\")).filter(_.length \u003e threshold).mkString(s\" ${comb} \")\n}\n\n// A custom linker\nval linker: Row \u003d\u003e String \u003d {\n    case row \u003d\u003e {\n        val title \u003d row.getString(row.fieldIndex(\"title\"))\n        val authors \u003d row.getString(row.fieldIndex(\"authors\"))\n    \n        val titleTokens \u003d tokenizer(title, 3)\n        val authorsTerms \u003d tokenizer(authors, 2)\n        \n        if (titleTokens.nonEmpty \u0026\u0026 authorsTerms.nonEmpty) {\n          s\"(title:(${titleTokens}) OR authors:(${authorsTerms}))\"\n        }\n        else if (titleTokens.nonEmpty){\n          s\"title:(${titleTokens})\"\n        }\n        else if (authorsTerms.nonEmpty){\n          s\"authors:(${authorsTerms})\"\n        }\n        else {\n          \"*:*\"\n        }\n    }\n}\n\nval linkedResults \u003d dblp.linkDataFrame(scholar, linker, 3)\n\nval linkageResults \u003d spark.createDataFrame(linkedResults.filter(_._2.nonEmpty).map{ case (scholar, topDocs) \u003d\u003e (topDocs.head.doc.textField(\"id\").head, scholar.getString(scholar.fieldIndex(\"id\")))})\n      .toDF(\"idDBLP\", \"idScholar\")\n\nval correctHits: Double \u003d linkageResults.join(groundTruthDF, groundTruthDF.col(\"idDBLP\").equalTo(linkageResults(\"idDBLP\")) \u0026\u0026  groundTruthDF.col(\"idScholar\").equalTo(linkageResults(\"idScholar\"))).count\n\nval total: Double \u003d groundTruthDF.count\nval accuracy \u003d correctHits / total\n\n\nprintln(\"********************************\")\nprintln(\"********************************\")\nprintln(s\"Accuracy of linkage is ${accuracy}\")\nprintln(\"********************************\")\nprintln(\"********************************\")",
      "dateUpdated": "Oct 16, 2016 8:35:14 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {},
          "map": {
            "baseMapType": "Streets",
            "isOnline": true,
            "pinCols": []
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1475350705777_450220362",
      "id": "20161001-155628_1046044654",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\ntokenizer: (s: String, threshold: Int, comb: String)String\n\nlinker: org.apache.spark.sql.Row \u003d\u003e String \u003d \u003cfunction1\u003e\n\nlinkedResults: org.apache.spark.rdd.RDD[(org.apache.spark.sql.Row, List[org.zouzias.spark.lucenerdd.models.SparkScoreDoc])] \u003d MapPartitionsRDD[886] at map at LuceneRDD.scala:177\n\nlinkageResults: org.apache.spark.sql.DataFrame \u003d [idDBLP: string, idScholar: string]\n\ncorrectHits: Double \u003d 5047.0\n\ntotal: Double \u003d 5347.0\n\naccuracy: Double \u003d 0.9438937722087152\n********************************\n********************************\nAccuracy of linkage is 0.9438937722087152\n********************************\n********************************\n"
      },
      "dateCreated": "Oct 1, 2016 7:38:25 AM",
      "dateStarted": "Oct 16, 2016 8:35:16 AM",
      "dateFinished": "Oct 16, 2016 8:36:10 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "",
      "dateUpdated": "Oct 16, 2016 8:35:14 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {},
          "map": {
            "baseMapType": "Streets",
            "isOnline": true,
            "pinCols": []
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1475531796415_-542312315",
      "id": "20161003-215636_1667429531",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": ""
      },
      "dateCreated": "Oct 3, 2016 9:56:36 AM",
      "dateStarted": "Oct 16, 2016 8:35:20 AM",
      "dateFinished": "Oct 16, 2016 8:36:10 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "/lucenerdd/linkage/scholar-vs-dblp",
  "id": "2BY8APKUF",
  "angularObjects": {},
  "config": {
    "looknfeel": "default"
  },
  "info": {}
}